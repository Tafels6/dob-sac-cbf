{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sac.sac_torch_new import Agent\n",
    "from env.car_2d_intersection import Car2DIntersection\n",
    "from cbf.cbf_intersection import cbf_casadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Car2DIntersection()\n",
    "agent = Agent(input_dims=(env.observation_space.shape[0]-1,), env=env,  # ATTENTION: minus 1 for diy env\n",
    "        n_actions=env.action_space.shape[0])\n",
    "n_games = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disturbance_observer(env, x, x_hat, a):\n",
    "    dt = env.dt\n",
    "    x_delta = x_hat - x\n",
    "    d_hat = -a * x_delta / (np.exp(a * dt) - 1)\n",
    "\n",
    "    return d_hat\n",
    "\n",
    "def state_predictor(env, x, x_hat, u, a):\n",
    "    dt = env.dt\n",
    "    x_delta = x_hat - x\n",
    "    d_hat = -a * x_delta / (np.exp(a * dt) - 1)\n",
    "\n",
    "    px, py, velocity, vx, vy, heading_angle, cos_theta, sin_theta = x\n",
    "    acceleration, front_wheel_angle = u\n",
    "    # beta = np.arctan(0.5 * np.tan(front_wheel_angle))\n",
    "    # angle_velocity = velocity * np.sin(beta) \n",
    "    angle_velocity = 0.5 * velocity * np.tan(front_wheel_angle)\n",
    "\n",
    "    # px, py, v, vx, vy, theta, cos, sin\n",
    "    obs_dt = np.array([velocity*np.cos(heading_angle),\n",
    "                      velocity*np.sin(heading_angle),\n",
    "                      acceleration,\n",
    "                      0,\n",
    "                      0,\n",
    "                      angle_velocity,\n",
    "                      0,\n",
    "                      0])\n",
    "    x_ = x + (obs_dt + d_hat - a * x_delta) * dt\n",
    "    x_[3:5] = np.array([np.cos(x_[-3])*x_[2],np.sin(x_[-3])*x_[2]])\n",
    "    x_[-2:] = np.array([np.cos(x_[-3]),np.sin(x_[-3])])\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trajectory_1(episode, obs_history, obstacles_history, sense_range, info, writer):\n",
    "    \"\"\"\n",
    "    Generates and saves an animated GIF of a car's trajectory and surrounding obstacles.\n",
    "\n",
    "    Parameters:\n",
    "        episode (int): Episode number.\n",
    "        obs_history (list): List of observations (positions) of the car.\n",
    "        obstacles_history (list): List of obstacle positions for each frame.\n",
    "        sense_range (float): Sensing range of the car.\n",
    "        info (str): Additional info to include in the file name.\n",
    "        writer (str): Writer to use for saving the GIF.\n",
    "        output_dir (str): Directory to save the GIF.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim([-15, 15])\n",
    "    ax.set_ylim([-15, 15])\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('X Coordinate')\n",
    "    plt.ylabel('Y Coordinate')\n",
    "    plt.title(f'Car Trajectory - Episode {episode}')\n",
    "    plt.grid()\n",
    "\n",
    "    line, = ax.plot([], [], marker='o', markersize=2, linestyle='-')\n",
    "    obstacles_patches = [patches.Circle((obstacle[0], obstacle[1]), 0.4, fill=False, color='red') for obstacle in obstacles_history[0]]\n",
    "    for patch in obstacles_patches:\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    # Adding lines and arcs for lanes and turns\n",
    "    # Implementation details are assumed to be correct and are not repeated here for brevity\n",
    "\n",
    "    current_pos, = ax.plot([], [], marker='o', markersize=5, color='green')\n",
    "    car_circle = patches.Circle((0, 0), sense_range, fill=False, color='green', linestyle='--') if sense_range != np.inf else None\n",
    "    if car_circle:\n",
    "        ax.add_patch(car_circle)\n",
    "\n",
    "    def update(frame):\n",
    "        line.set_data([obs[0] for obs in obs_history[:frame+1]], [obs[1] for obs in obs_history[:frame+1]])\n",
    "        current_pos.set_data([obs_history[frame][0]], [obs_history[frame][1]])\n",
    "        if car_circle:\n",
    "            car_circle.center = obs_history[frame][0], obs_history[frame][1]\n",
    "        for patch, obstacle in zip(obstacles_patches, obstacles_history[frame]):\n",
    "            patch.center = (obstacle[0], obstacle[1])\n",
    "        return [line] + obstacles_patches\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=len(obs_history), interval=100, blit=True)\n",
    "    gif_path = f'tmp/plot/epi_{episode}_{info}.gif'\n",
    "    anim.save(gif_path, writer='pillow', fps=30)\n",
    "    plt.close(fig)\n",
    "    # writer.add_figure(f\"Figure/{episode}\", fig, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obs(writer,observation,observation_hat,i,step):\n",
    "    writer.add_scalar(f\"Observation/Episode_{i}/Step/x\", observation[0], step)\n",
    "    writer.add_scalar(f\"Observation/Episode_{i}/Step/y\", observation[1], step)\n",
    "    writer.add_scalar(f\"Observation/Episode_{i}/Step/v\", observation[2], step)\n",
    "    writer.add_scalar(f\"Observation/Episode_{i}/Step/theta\", observation[5], step)\n",
    "    writer.add_scalar(f\"Observation_hat/Episode_{i}/Step/x\", observation_hat[0], step)\n",
    "    writer.add_scalar(f\"Observation_hat/Episode_{i}/Step/y\", observation_hat[1], step)\n",
    "    writer.add_scalar(f\"Observation_hat/Episode_{i}/Step/v\", observation_hat[2], step)\n",
    "    writer.add_scalar(f\"Observation_hat/Episode_{i}/Step/theta\", observation_hat[5], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tmp/runs')\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "global_step = 0\n",
    "env.set_seed(4)\n",
    "\n",
    "sense_range = np.inf\n",
    "use_DOB = True\n",
    "use_CBF = True\n",
    "save_runs = False\n",
    "real_world = True\n",
    "high_order_model = True\n",
    "\n",
    "for i in range(n_games):\n",
    "# for i in range(1):\n",
    "    observation,_ = env.reset()  # px, py, v, vx, vy, theta, cos, sin\n",
    "    modified_observation = np.delete(observation, -3)  # delete theta for better training\n",
    "    observation_hat = np.array(observation)\n",
    "    modified_observation_hat = np.delete(observation_hat, -3)\n",
    "    dob_param = 1e-2\n",
    "    done = False\n",
    "    score = 0\n",
    "    info = {}\n",
    "    step = 0\n",
    "    reward = 0\n",
    "    observation_history = []\n",
    "    obstacles_history = []\n",
    "    observation_history.append(np.array(observation))\n",
    "    obstacles_history.append(np.array(env.other_cars))\n",
    "    last_action = np.zeros(env.action_space.shape[0])\n",
    "    action_max = np.zeros(env.action_space.shape[0])\n",
    "    while not done and step < 500:\n",
    "        # early stop\n",
    "        if np.any(abs(observation[:2])>20):\n",
    "            break\n",
    "        if save_runs:\n",
    "            save_obs(writer,observation,observation_hat,i,step)\n",
    "        action = agent.choose_action(modified_observation_hat)\n",
    "        d_hat = np.zeros(observation.shape)\n",
    "        if use_DOB:\n",
    "            d_hat = disturbance_observer(env, observation, observation_hat, dob_param)            \n",
    "        if use_CBF:\n",
    "            action = np.array(cbf_casadi(env, observation, action, sense_range, d_hat))\n",
    "\n",
    "        observation_hat = state_predictor(env, observation, observation_hat, action, dob_param)\n",
    "        observation_, reward, done,_, info = env.step(action, last_action, real_world, high_order_model)\n",
    "        modified_observation_ = np.delete(observation_, -3)\n",
    "        modified_observation_hat_ = np.delete(observation_hat, -3)\n",
    "        score += reward\n",
    "        \n",
    "        if use_DOB:\n",
    "            agent.remember(modified_observation_hat, action, reward, modified_observation_hat_, done)\n",
    "        else:\n",
    "            agent.remember(modified_observation, action, reward, modified_observation_, done)\n",
    "        \n",
    "        # print('observation', observation, 'modified_observation_hat', modified_observation_hat,'modified_observation_hat_', modified_observation_hat_)\n",
    "        \n",
    "        agent.learn(i, step, global_step, writer, save_runs)\n",
    "        observation = observation_\n",
    "        modified_observation = modified_observation_\n",
    "        modified_observation_hat = modified_observation_hat_\n",
    "        last_action = action\n",
    "        # print('observation: ',observation)\n",
    "        observation_history.append(np.array(observation))\n",
    "        obstacles_history.append(np.array(env.other_cars))\n",
    "        step += 1\n",
    "        global_step += 1\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if save_runs:\n",
    "        writer.add_scalar('avg_score/Episode', avg_score, i)\n",
    "\n",
    "    np.set_printoptions(formatter={'float': '{:0.2f}'.format})\n",
    "    print('episode', i, ', after', step, 'steps: ', info, ', last state: ', observation[[0,1,2,5]], ', with reward: ', np.array([reward]))\n",
    "    \n",
    "    if info == {'goal_reached'}:\n",
    "    # if any('collision' in element for element in info):\n",
    "    # if info == {'collision'} or info == {'goal_reached'}:\n",
    "        save_trajectory_1(i,observation_history,obstacles_history,sense_range,info,writer)\n",
    "        # break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
